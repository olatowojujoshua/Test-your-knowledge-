{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "77f1ec01",
      "metadata": {
        "id": "77f1ec01"
      },
      "source": [
        "\n",
        "# Negation Handling in Sentiment Classification\n",
        "\n",
        "In this activity, we will explore **how negation changes the meaning of text** and how to account for it in sentiment analysis.  \n",
        "Negation words like *not*, *never*, or *didn't* can completely flip the sentiment of a sentence (for example, *“good”* vs. *“not good”*).\n",
        "\n",
        "We will experiment with two models to see the effect:\n",
        "1. A **baseline model** using a standard TF–IDF + Logistic Regression pipeline.  \n",
        "2. A **negation-aware model** that preprocesses text to merge negation words with the following token (e.g., *not good → not_good*).\n",
        "\n",
        "By comparing their performance, we’ll understand how simple linguistic preprocessing can improve or alter model behavior."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "77bf8470",
      "metadata": {
        "id": "77bf8470"
      },
      "source": [
        "## Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "29b0bb38",
      "metadata": {
        "id": "29b0bb38"
      },
      "outputs": [],
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "428b78f0",
      "metadata": {
        "id": "428b78f0"
      },
      "source": [
        "## Step 1: Use the Provided Dataset\n",
        "\n",
        "In this activity, we’ll work with a **predefined dataset** of short movie reviews.  \n",
        "The dataset includes examples with and without **negation**, such as *“The movie was good”* and *“The movie was not good.”*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "cd123367",
      "metadata": {
        "id": "cd123367"
      },
      "outputs": [],
      "source": [
        "\n",
        "corpus = [\n",
        "    # Positive without negation\n",
        "    (\"The movie was good\", 1),\n",
        "    (\"This is an excellent film\", 1),\n",
        "    (\"The movie was amazing\", 1),\n",
        "    (\"The film is wonderful\", 1),\n",
        "    (\"I loved every minute of it\", 1),\n",
        "    (\"Outstanding performance by all actors\", 1),\n",
        "    (\"One of the best movies I've seen\", 1),\n",
        "    (\"The cinematography was beautiful\", 1),\n",
        "    (\"Perfect soundtrack and visuals\", 1),\n",
        "    (\"Highly entertaining and engaging\", 1),\n",
        "    (\"The acting was superb\", 1),\n",
        "    (\"Great storytelling and pacing\", 1),\n",
        "    (\"Absolutely fantastic experience\", 1),\n",
        "    (\"I thoroughly enjoyed this film\", 1),\n",
        "    (\"Brilliant script and direction\", 1),\n",
        "    (\"The plot was captivating\", 1),\n",
        "    (\"Wonderful character development\", 1),\n",
        "    (\"Top quality production\", 1),\n",
        "    (\"I would watch it again\", 1),\n",
        "    (\"Exceptional movie experience\", 1),\n",
        "\n",
        "    # Negative without negation\n",
        "    (\"The acting was terrible\", 0),\n",
        "    (\"This film was boring\", 0),\n",
        "    (\"Waste of time and money\", 0),\n",
        "    (\"Poorly written script\", 0),\n",
        "    (\"Confusing and hard to follow\", 0),\n",
        "    (\"The plot made no sense\", 0),\n",
        "    (\"Weak character development\", 0),\n",
        "    (\"Disappointing overall experience\", 0),\n",
        "    (\"Bad cinematography and editing\", 0),\n",
        "    (\"Not worth the ticket price\", 0),\n",
        "    (\"The dialogue was awful\", 0),\n",
        "    (\"Cheap production quality\", 0),\n",
        "    (\"I regret watching this\", 0),\n",
        "    (\"Boring and predictable story\", 0),\n",
        "    (\"Terrible acting from everyone\", 0),\n",
        "    (\"Poorly executed concept\", 0),\n",
        "    (\"The worst movie I've seen\", 0),\n",
        "    (\"Complete waste of time\", 0),\n",
        "    (\"Uninteresting and dull\", 0),\n",
        "    (\"I hated every minute\", 0),\n",
        "\n",
        "    # Positive with negation (negation flips to positive)\n",
        "    (\"The plot was not bad\", 1),\n",
        "    (\"It was not terrible at all\", 1),\n",
        "    (\"I can't believe how good it was\", 1),\n",
        "    (\"It wasn't bad\", 1),\n",
        "    (\"The movie is not boring\", 1),\n",
        "    (\"I couldn't believe how great it was\", 1),\n",
        "    (\"It's not a waste of time\", 1),\n",
        "    (\"The acting wasn't terrible\", 1),\n",
        "    (\"I can't say I didn't enjoy it\", 1),\n",
        "    (\"The story isn't confusing\", 1),\n",
        "    (\"It wasn't disappointing at all\", 1),\n",
        "    (\"I can't find anything wrong with it\", 1),\n",
        "    (\"The film is not poorly made\", 1),\n",
        "    (\"I wouldn't say it's bad\", 1),\n",
        "    (\"It wasn't what I expected in a good way\", 1),\n",
        "\n",
        "    # Negative with negation (negation makes it negative)\n",
        "    (\"The movie was not good\", 0),\n",
        "    (\"I didn't like the film\", 0),\n",
        "    (\"I do not recommend this movie\", 0),\n",
        "    (\"I cannot say I enjoyed it\", 0),\n",
        "    (\"The story is not interesting\", 0),\n",
        "    (\"I don't think it's worth watching\", 0),\n",
        "    (\"The acting wasn't good\", 0),\n",
        "    (\"I can't say I enjoyed it\", 0),\n",
        "    (\"The plot is not engaging\", 0),\n",
        "    (\"I didn't find it entertaining\", 0),\n",
        "    (\"The film is not worth watching\", 0),\n",
        "    (\"I can't recommend this movie\", 0),\n",
        "    (\"The story doesn't make sense\", 0),\n",
        "    (\"I wouldn't watch it again\", 0),\n",
        "    (\"It's not what I expected in a bad way\", 0),\n",
        "    (\"The movie isn't entertaining\", 0),\n",
        "    (\"I don't understand the hype\", 0),\n",
        "    (\"The acting can't save this film\", 0),\n",
        "    (\"I won't recommend this to anyone\", 0),\n",
        "    (\"The plot doesn't work at all\", 0),\n",
        "]\n",
        "\n",
        "\n",
        "# Separate features (X) and labels (y)\n",
        "X = [t for t, y in corpus]\n",
        "y = [y for t, y in corpus]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a468d29a",
      "metadata": {
        "id": "a468d29a"
      },
      "source": [
        "## Step 2.1: Prepare the Data\n",
        "Write the code to separate the text and labels, and then split them into training and test sets using an 80/20 ratio. Do not forget to stratify based on labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "d5513b53",
      "metadata": {
        "id": "d5513b53"
      },
      "outputs": [],
      "source": [
        "import spacy\n",
        "from spacy import displacy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the dataset into training and testing (80/20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42, stratify=y\n",
        ")\n",
        "\n",
        "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IxB_gtwuoi0p",
        "outputId": "a9a29078-5bf0-4206-c640-bc5f2b2220ca"
      },
      "id": "IxB_gtwuoi0p",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 60, Test samples: 15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6301e284",
      "metadata": {
        "id": "6301e284"
      },
      "source": [
        "## Step 2.2: Your preprocessing Fucntion\n",
        "Later in this activity, you will also use the following **preprocessing function** inside the negation-aware pipeline.  \n",
        "This function merges negation words (like *not good → not_good*) so the model can treat them as single meaningful tokens."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "229dfd5e",
      "metadata": {
        "id": "229dfd5e"
      },
      "outputs": [],
      "source": [
        "def preprocess_negation(text):\n",
        "    text = re.sub(r'\\b(not|n\\'t|cannot|can\\'t|don\\'t|didn\\'t|doesn\\'t|won\\'t|wasn\\'t|isn\\'t|couldn\\'t)\\s+(\\w+)',\n",
        "                  r'\\1_\\2', text, flags=re.IGNORECASE)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67beacdb",
      "metadata": {
        "id": "67beacdb"
      },
      "source": [
        "#### Can you understand what does it do?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It detects negation words followed by another word and combines them with an underscore (e.g., “not good” → “not_good”) so the model can understand negation as a single unit."
      ],
      "metadata": {
        "id": "ltKbIievqK02"
      },
      "id": "ltKbIievqK02"
    },
    {
      "cell_type": "markdown",
      "id": "d8421b5a",
      "metadata": {
        "id": "d8421b5a"
      },
      "source": [
        "## Step 3: Define and Train the Models\n",
        "\n",
        "In this step, you will set up two **Logistic Regression models** for sentiment classification:\n",
        "\n",
        "1. **Baseline model** – uses standard TF-IDF vectorization without any special handling for negation.  \n",
        "2. **Negation-aware model** – applies the `preprocess_negation()` function before vectorization to treat phrases like “not good” as a single token.\n",
        "\n",
        "Both models will be trained on the same data.  \n",
        "After training, we will later compare their performance to see how much the negation-aware preprocessing improves sentiment detection."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "286ee368",
      "metadata": {
        "id": "286ee368"
      },
      "outputs": [],
      "source": [
        "def preprocess_negation(text):\n",
        "    import re\n",
        "    return re.sub(\n",
        "        r\"\\b(not|n't|cannot|can't|don't|didn't|doesn't|won't|wasn't|isn't|couldn't)\\s+(\\w+)\",\n",
        "        r\"\\1_\\2\",\n",
        "        text,\n",
        "        flags=re.IGNORECASE\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "18097715",
      "metadata": {
        "id": "18097715"
      },
      "source": [
        "## Step 4: Evaluate and Compare the Models\n",
        "\n",
        "Now it’s time to **evaluate both models** on the test set.\n",
        "\n",
        "Run the following code to:\n",
        "- Generate predictions from the **baseline** and **negation-aware** models.  \n",
        "- Compute their **accuracy** and **confusion matrices**.  \n",
        "- Compare results side by side to see whether the negation-aware preprocessing improves performance.\n",
        "\n",
        "Pay attention to the printed accuracies and the confusion matrices — they will reveal how well each model handles sentences containing negations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "4293f29b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4293f29b",
        "outputId": "cf8f63dc-c8f9-44eb-f64b-d768dd75d898"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Models trained.\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Baseline: no negation handling\n",
        "baseline_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2))),\n",
        "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "baseline_clf.fit(X_train, y_train)\n",
        "\n",
        "# Negation-aware: uses the preprocessor\n",
        "negation_clf = Pipeline([\n",
        "    (\"tfidf\", TfidfVectorizer(ngram_range=(1, 2), preprocessor=preprocess_negation)),\n",
        "    (\"logreg\", LogisticRegression(max_iter=1000))\n",
        "])\n",
        "negation_clf.fit(X_train, y_train)\n",
        "\n",
        "print(\"Models trained.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# evaluaton and comparisons"
      ],
      "metadata": {
        "id": "OZqbnjt9rRGg"
      },
      "id": "OZqbnjt9rRGg"
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "\n",
        "# Predict\n",
        "pred_base = baseline_clf.predict(X_test)\n",
        "pred_neg  = negation_clf.predict(X_test)\n",
        "\n",
        "# Accuracy\n",
        "acc_base = accuracy_score(y_test, pred_base)\n",
        "acc_neg  = accuracy_score(y_test, pred_neg)\n",
        "print(f\"Baseline accuracy:       {acc_base:.3f}\")\n",
        "print(f\"Negation-aware accuracy: {acc_neg:.3f}\")\n",
        "\n",
        "# Confusion matrices\n",
        "print(\"\\nConfusion matrix (baseline):\")\n",
        "print(confusion_matrix(y_test, pred_base))\n",
        "\n",
        "print(\"\\nConfusion matrix (negation-aware):\")\n",
        "print(confusion_matrix(y_test, pred_neg))\n",
        "\n",
        "# Quick sanity-check sentences with negation\n",
        "examples = [\n",
        "    \"not good\",\n",
        "    \"not bad\",\n",
        "    \"I don't dislike it\",\n",
        "    \"I wouldn't recommend it\",\n",
        "    \"I can't say it's terrible\",\n",
        "    \"This is not amazing\",\n",
        "]\n",
        "for s in examples:\n",
        "    b = baseline_clf.predict([s])[0]\n",
        "    n = negation_clf.predict([s])[0]\n",
        "    print(f\"\\n{s}\")\n",
        "    print(\"  Baseline     →\", \"Positive\" if b==1 else \"Negative\")\n",
        "    print(\"  Negation-aware →\", \"Positive\" if n==1 else \"Negative\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-sQ_V577rScK",
        "outputId": "5fabb93a-d91e-4b29-e9a8-ca1ddda9a1b4"
      },
      "id": "-sQ_V577rScK",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Baseline accuracy:       0.333\n",
            "Negation-aware accuracy: 0.333\n",
            "\n",
            "Confusion matrix (baseline):\n",
            "[[5 3]\n",
            " [7 0]]\n",
            "\n",
            "Confusion matrix (negation-aware):\n",
            "[[5 3]\n",
            " [7 0]]\n",
            "\n",
            "not good\n",
            "  Baseline     → Positive\n",
            "  Negation-aware → Negative\n",
            "\n",
            "not bad\n",
            "  Baseline     → Positive\n",
            "  Negation-aware → Positive\n",
            "\n",
            "I don't dislike it\n",
            "  Baseline     → Negative\n",
            "  Negation-aware → Negative\n",
            "\n",
            "I wouldn't recommend it\n",
            "  Baseline     → Negative\n",
            "  Negation-aware → Negative\n",
            "\n",
            "I can't say it's terrible\n",
            "  Baseline     → Negative\n",
            "  Negation-aware → Negative\n",
            "\n",
            "This is not amazing\n",
            "  Baseline     → Negative\n",
            "  Negation-aware → Negative\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "global",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}